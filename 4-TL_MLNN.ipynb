{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using MLNN\n",
    "\n",
    "In this notebook, a transfer learning (TL) approach is followed to solve a cancer prediction task on gene-expression samples from a concrete tumor type. We perform a TL approach by pre-training a MLNN on the non-Lung cancer samples from the TCGA PanCancer dataset, and then fine-tune the model on the Lung cancer dataset (see `PanCancer_Lung_Split` notebook). As input data, we use the gene expression profiles directly modeled as numeric vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Auxiliary components\n",
    "from bio_dl_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progression free-interval\n",
    "\n",
    "Here, we predict the discrete progression-free interval (PFI) of each patient (sample), which correponds to a binary classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define survival variable of interest\n",
    "surv_variable = \"PFI\"\n",
    "surv_variable_time = \"PFI.time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-Lung cancer\n",
    "\n",
    "We only use the non-Lung tumor samples from the TCGA PanCancer dataset with the survival information of interest associated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9374, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load samples-info dataset\n",
    "Y_info = pd.read_hdf(\"data/PanCancer/non_Lung_pancan.h5\", \n",
    "                     key=\"sample_type\")\n",
    "Y_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9374, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load survival clinical outcome dataset\n",
    "Y_surv = pd.read_hdf(\"data/PanCancer/non_Lung_pancan.h5\", \n",
    "                     key=\"sample_clinical\")\n",
    "Y_surv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tumor     8771\n",
       "Normal     603\n",
       "Name: tumor_normal, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tumor-normal distribution\n",
    "Y_info.tumor_normal.value_counts(normalize=False, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8771, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter tumor samples from survival clinical outcome dataset\n",
    "Y_surv = Y_surv.loc[Y_info.tumor_normal==\"Tumor\"]\n",
    "Y_surv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8563, 33)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where surv_variable or surv_variable_time is NA\n",
    "Y_surv.dropna(subset=[surv_variable, surv_variable_time], inplace=True)\n",
    "Y_surv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2992.000000\n",
       "mean       625.818516\n",
       "std        817.163242\n",
       "min          0.000000\n",
       "25%        188.000000\n",
       "50%        370.000000\n",
       "75%        729.250000\n",
       "max      10334.000000\n",
       "Name: PFI.time, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Event PFI samples time distribution\n",
    "Y_surv.loc[Y_surv.PFI==1.0]['PFI.time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5571.000000\n",
       "mean      1050.329564\n",
       "std       1017.383207\n",
       "min          0.000000\n",
       "25%        388.000000\n",
       "50%        741.000000\n",
       "75%       1409.000000\n",
       "max      11217.000000\n",
       "Name: PFI.time, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Censored PFI samples time distribution\n",
    "Y_surv.loc[Y_surv.PFI==0.0]['PFI.time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a discrete time class variable using the fixed-time point selected in `Lung_PFI_Prediction` notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7707,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = 230\n",
    "Y_surv_disc = Y_surv[['PFI', 'PFI.time']].apply(\n",
    "    lambda row: survival_fixed_time(time, row['PFI.time'], row['PFI']), axis=1)\n",
    "\n",
    "Y_surv_disc.dropna(inplace=True)\n",
    "Y_surv_disc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12222654729466718"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Event class fraction\n",
    "sum(Y_surv_disc)/len(Y_surv_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load gene-exp vectors: this dataset was obtained from the final KEGG BRITE functional hierarchies dataset generated in\n",
    "# 1-KEGG_BRITE_Hierarchy notebook, by selecting only the columns corresponding to PanCancer samples, removing the \n",
    "# duplicated genes (rows) and transposing it\n",
    "df_gene_exp = pd.read_csv(\"./KEGG_gene_exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10535, 7509)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gene_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000187961.13</th>\n",
       "      <th>ENSG00000188290.10</th>\n",
       "      <th>ENSG00000187608.8</th>\n",
       "      <th>ENSG00000188157.13</th>\n",
       "      <th>ENSG00000186891.13</th>\n",
       "      <th>ENSG00000186827.10</th>\n",
       "      <th>ENSG00000184163.3</th>\n",
       "      <th>ENSG00000162572.19</th>\n",
       "      <th>ENSG00000131584.18</th>\n",
       "      <th>ENSG00000169962.4</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000067048.16</th>\n",
       "      <th>ENSG00000183878.15</th>\n",
       "      <th>ENSG00000154620.5</th>\n",
       "      <th>ENSG00000165246.12</th>\n",
       "      <th>ENSG00000012817.15</th>\n",
       "      <th>ENSG00000198692.9</th>\n",
       "      <th>ENSG00000105227.14</th>\n",
       "      <th>ENSG00000164237.8</th>\n",
       "      <th>ENSG00000175048.16</th>\n",
       "      <th>ENSG00000188706.12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA.02.0047.01</th>\n",
       "      <td>1.3225</td>\n",
       "      <td>4.1604</td>\n",
       "      <td>5.8166</td>\n",
       "      <td>6.3983</td>\n",
       "      <td>-1.9942</td>\n",
       "      <td>0.7493</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>5.7493</td>\n",
       "      <td>-2.1779</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5760</td>\n",
       "      <td>2.1013</td>\n",
       "      <td>1.2815</td>\n",
       "      <td>3.6497</td>\n",
       "      <td>3.7614</td>\n",
       "      <td>4.6508</td>\n",
       "      <td>1.2815</td>\n",
       "      <td>4.3618</td>\n",
       "      <td>4.9426</td>\n",
       "      <td>5.7748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.02.0055.01</th>\n",
       "      <td>2.3135</td>\n",
       "      <td>3.6148</td>\n",
       "      <td>6.9599</td>\n",
       "      <td>4.3356</td>\n",
       "      <td>2.9281</td>\n",
       "      <td>1.5266</td>\n",
       "      <td>0.4016</td>\n",
       "      <td>1.1316</td>\n",
       "      <td>4.1692</td>\n",
       "      <td>-3.4580</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.8160</td>\n",
       "      <td>-6.5064</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>-5.5735</td>\n",
       "      <td>-3.0469</td>\n",
       "      <td>-4.0350</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>2.5924</td>\n",
       "      <td>2.9488</td>\n",
       "      <td>5.6056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.02.2483.01</th>\n",
       "      <td>2.5707</td>\n",
       "      <td>3.8729</td>\n",
       "      <td>5.9072</td>\n",
       "      <td>6.3946</td>\n",
       "      <td>-1.9379</td>\n",
       "      <td>2.2813</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>5.3995</td>\n",
       "      <td>-2.9324</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8391</td>\n",
       "      <td>1.2085</td>\n",
       "      <td>1.7744</td>\n",
       "      <td>3.0428</td>\n",
       "      <td>2.7270</td>\n",
       "      <td>5.3042</td>\n",
       "      <td>-1.1172</td>\n",
       "      <td>3.5523</td>\n",
       "      <td>3.3450</td>\n",
       "      <td>4.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.02.2485.01</th>\n",
       "      <td>3.3814</td>\n",
       "      <td>5.8875</td>\n",
       "      <td>9.9433</td>\n",
       "      <td>6.2132</td>\n",
       "      <td>-0.8599</td>\n",
       "      <td>1.3051</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>1.8801</td>\n",
       "      <td>6.0637</td>\n",
       "      <td>-2.4659</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1036</td>\n",
       "      <td>1.5661</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>2.7095</td>\n",
       "      <td>4.0019</td>\n",
       "      <td>4.8090</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>3.6635</td>\n",
       "      <td>3.9468</td>\n",
       "      <td>4.5571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.04.1331.01</th>\n",
       "      <td>2.0500</td>\n",
       "      <td>4.7661</td>\n",
       "      <td>8.6119</td>\n",
       "      <td>6.6414</td>\n",
       "      <td>-1.6850</td>\n",
       "      <td>1.3846</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>2.4831</td>\n",
       "      <td>3.6961</td>\n",
       "      <td>-3.1714</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>-9.9658</td>\n",
       "      <td>0.5955</td>\n",
       "      <td>4.3660</td>\n",
       "      <td>1.4547</td>\n",
       "      <td>5.1486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7509 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ENSG00000187961.13  ENSG00000188290.10  ENSG00000187608.8  \\\n",
       "TCGA.02.0047.01              1.3225              4.1604             5.8166   \n",
       "TCGA.02.0055.01              2.3135              3.6148             6.9599   \n",
       "TCGA.02.2483.01              2.5707              3.8729             5.9072   \n",
       "TCGA.02.2485.01              3.3814              5.8875             9.9433   \n",
       "TCGA.04.1331.01              2.0500              4.7661             8.6119   \n",
       "\n",
       "                 ENSG00000188157.13  ENSG00000186891.13  ENSG00000186827.10  \\\n",
       "TCGA.02.0047.01              6.3983             -1.9942              0.7493   \n",
       "TCGA.02.0055.01              4.3356              2.9281              1.5266   \n",
       "TCGA.02.2483.01              6.3946             -1.9379              2.2813   \n",
       "TCGA.02.2485.01              6.2132             -0.8599              1.3051   \n",
       "TCGA.04.1331.01              6.6414             -1.6850              1.3846   \n",
       "\n",
       "                 ENSG00000184163.3  ENSG00000162572.19  ENSG00000131584.18  \\\n",
       "TCGA.02.0047.01             0.3346              0.7321              5.7493   \n",
       "TCGA.02.0055.01             0.4016              1.1316              4.1692   \n",
       "TCGA.02.2483.01             0.2029              0.9419              5.3995   \n",
       "TCGA.02.2485.01             0.0014              1.8801              6.0637   \n",
       "TCGA.04.1331.01             0.7664              2.4831              3.6961   \n",
       "\n",
       "                 ENSG00000169962.4         ...          ENSG00000067048.16  \\\n",
       "TCGA.02.0047.01            -2.1779         ...                      4.5760   \n",
       "TCGA.02.0055.01            -3.4580         ...                     -3.8160   \n",
       "TCGA.02.2483.01            -2.9324         ...                      3.8391   \n",
       "TCGA.02.2485.01            -2.4659         ...                      4.1036   \n",
       "TCGA.04.1331.01            -3.1714         ...                     -9.9658   \n",
       "\n",
       "                 ENSG00000183878.15  ENSG00000154620.5  ENSG00000165246.12  \\\n",
       "TCGA.02.0047.01              2.1013             1.2815              3.6497   \n",
       "TCGA.02.0055.01             -6.5064            -9.9658             -5.5735   \n",
       "TCGA.02.2483.01              1.2085             1.7744              3.0428   \n",
       "TCGA.02.2485.01              1.5661             0.5568              2.7095   \n",
       "TCGA.04.1331.01             -9.9658            -9.9658             -9.9658   \n",
       "\n",
       "                 ENSG00000012817.15  ENSG00000198692.9  ENSG00000105227.14  \\\n",
       "TCGA.02.0047.01              3.7614             4.6508              1.2815   \n",
       "TCGA.02.0055.01             -3.0469            -4.0350              0.2881   \n",
       "TCGA.02.2483.01              2.7270             5.3042             -1.1172   \n",
       "TCGA.02.2485.01              4.0019             4.8090              0.9642   \n",
       "TCGA.04.1331.01             -9.9658            -9.9658              0.5955   \n",
       "\n",
       "                 ENSG00000164237.8  ENSG00000175048.16  ENSG00000188706.12  \n",
       "TCGA.02.0047.01             4.3618              4.9426              5.7748  \n",
       "TCGA.02.0055.01             2.5924              2.9488              5.6056  \n",
       "TCGA.02.2483.01             3.5523              3.3450              4.8360  \n",
       "TCGA.02.2485.01             3.6635              3.9468              4.5571  \n",
       "TCGA.04.1331.01             4.3660              1.4547              5.1486  \n",
       "\n",
       "[5 rows x 7509 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gene_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples with discrete time survival information associated\n",
    "df_gene_exp_disc = df_gene_exp.loc[[s.replace(\"-\", \".\") for s in Y_surv_disc.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7707, 7509)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gene_exp_disc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the binary class variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert discrete time survival numerical variables into binary variables\n",
    "Y_surv_disc_class = LabelEncoder().fit_transform(Y_surv_disc)\n",
    "np.unique(Y_surv_disc_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7707,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_surv_disc_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lung\n",
    "\n",
    "We also load the Lung tumor samples from the TCGA PanCancer dataset with the survival information of interest associated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 33)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load samples-info dataset\n",
    "Y_info_ft = pd.read_hdf(\"../data/PanCancer/Lung_pancan.h5\", key=\"sample\")\n",
    "# Load survival clinical outcome dataset\n",
    "Y_surv_ft = pd.read_hdf(\"../data/PanCancer/Lung_pancan.h5\", key=\"survival_outcome\")\n",
    "# Filter tumor samples from survival clinical outcome dataset\n",
    "Y_surv_ft = Y_surv_ft.loc[Y_info_ft.tumor_normal==\"Tumor\"]\n",
    "# Drop rows where surv_variable or surv_variable_time is NA\n",
    "Y_surv_ft.dropna(subset=[surv_variable, surv_variable_time], inplace=True)\n",
    "Y_surv_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = 230\n",
    "Y_surv_disc_ft = Y_surv_ft[['PFI', 'PFI.time']].apply(\n",
    "    lambda row: survival_fixed_time(time, row['PFI.time'], row['PFI']), axis=1)\n",
    "\n",
    "Y_surv_disc_ft.dropna(inplace=True)\n",
    "Y_surv_disc_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09473684210526316"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Event class fraction\n",
    "sum(Y_surv_disc_ft)/len(Y_surv_disc_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples with discrete time survival information associated\n",
    "df_gene_exp_disc_ft = df_gene_exp.loc[[s.replace(\"-\", \".\") for s in Y_surv_disc_ft.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 7509)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gene_exp_disc_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the binary class variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert discrete time survival numerical variables into binary variables\n",
    "Y_surv_disc_class_ft = LabelEncoder().fit_transform(Y_surv_disc_ft)\n",
    "Y_surv_disc_class_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join PT and FT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use bayesian-optimization to perform the hyper-parameters tuning of a MLNN architecture, using a cross-validation (CV) procedure. Random over-sampling is used both on pre-training and fine-tuning phases to deal with the severe class imbalance present in both non-Lung and Lung cancer datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Define training datasets\n",
    "X = df_gene_exp_disc_ft\n",
    "y = Y_surv_disc_class_ft\n",
    "\n",
    "# Define the scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Define re-sampling method\n",
    "ros = RandomOverSampler(random_state=69)\n",
    "\n",
    "# Define cross-validation train-test splits\n",
    "cv_split = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=23)\n",
    "\n",
    "# Define evaluation metrics\n",
    "model_sel_metric = 'auc'\n",
    "eval_metric = {'auc': make_scorer(roc_auc_score, needs_proba=True), \n",
    "               'acc': make_scorer(opt_accuracy_score, needs_proba=True), \n",
    "               'sens': make_scorer(opt_sensitivity_score, needs_proba=True),\n",
    "               'spec': make_scorer(opt_specificity_score, needs_proba=True),\n",
    "               'prec': make_scorer(opt_precision_score, needs_proba=True),\n",
    "               'f1': make_scorer(opt_f1_score, needs_proba=True),\n",
    "               'mcc': make_scorer(opt_mcc_score, needs_proba=True),\n",
    "               'thres': make_scorer(opt_threshold_score, needs_proba=True)}\n",
    "\n",
    "# Bayesian-Optimization parameters\n",
    "n_iter = 100\n",
    "random_state = 666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# Define the MLNN hyperparameters space\n",
    "params_space = {\n",
    "    # PT hyper-param\n",
    "    # We assume that the base model contains 2 dense layers\n",
    "    'clf__pt_params': hp.choice('pt_params', \n",
    "                [{'clf__dense_choice': hp.choice('dense_num_layers',\n",
    "                             [{#layers 2\n",
    "                               'clf__add_dense': 0,\n",
    "                               'clf__dense_unit_1': hp.choice('2dense_unit_1', [1000, 1500, 2000, 2350, 2700]),\n",
    "                               'clf__dense_unit_2': hp.choice('2dense_unit_2', [50, 100, 250, 500, 800]),\n",
    "                               \n",
    "                               'clf__dense_dropout_1': hp.choice('2dense_dropout_1', [0.2, 0.4, 0.6, 0.8]),\n",
    "                               'clf__dense_dropout_2': hp.choice('2dense_dropout_2', [0.2, 0.4, 0.6, 0.8])\n",
    "                              },\n",
    "                              {#layers 3\n",
    "                               'clf__add_dense': 1,\n",
    "                               'clf__dense_unit_1': hp.choice('3dense_unit_1', [1500, 1750, 2000, 2250, 2500, 2700]),\n",
    "                               'clf__dense_unit_2': hp.choice('3dense_unit_2', [200, 400, 700, 1000]),\n",
    "                               'clf__dense_unit_3': hp.choice('3dense_unit_3', [30, 80, 120, 160]),\n",
    "                               \n",
    "                               'clf__dense_activation_3': 'relu',\n",
    "                               \n",
    "                               'clf__dense_dropout_1': hp.choice('3dense_dropout_1', [0.2, 0.4, 0.6, 0.8]),\n",
    "                               'clf__dense_dropout_2': hp.choice('3dense_dropout_2', [0.2, 0.4, 0.6, 0.8]),\n",
    "                               'clf__dense_dropout_3': hp.choice('3dense_dropout_3', [0.2, 0.4, 0.6, 0.8])\n",
    "                              }]),\n",
    "                  \n",
    "               'clf__batch_size': hp.choice('batch_size_pt', [64, 128, 256, 384, 512]),\n",
    "               'clf__lr': hp.loguniform('lr_pt', np.log(1e-3), np.log(1e-1)),\n",
    "               # Re-sampling hyper-params\n",
    "               're_sample_pt__sampling_strategy': hp.choice('sampling_strategy_pt', [1, 1/2, 1/3, 1/4])}]),\n",
    "    \n",
    "    'clf__ft_params': hp.choice('ft_params', \n",
    "                [{'clf__batch_size': hp.choice('batch_size_ft', [32, 80, 128, 192, 256]),\n",
    "                  'clf__lr': hp.loguniform('lr_ft', np.log(5e-4), np.log(1e-1)),\n",
    "                  # Re-sampling hyper-params\n",
    "                  're_sample_ft__sampling_strategy': hp.choice('sampling_strategy_ft', [1, 1/2, 1/3, 1/4])}])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define PT MLNN estimator\n",
    "pre_model_path = 'keras-models/ros_mlnn_pt_ft_disc_pfi_x.h5'\n",
    "mlnn_pt = SklearnMLNN(input_shape=X.shape[1], dense_unit={}, dense_activation={1: 'relu', 2: 'relu'}, \n",
    "                 dense_dropout={}, output_unit=1, output_activation='sigmoid', \n",
    "                 optimizer_name='adam', loss_function='binary_crossentropy', epoch=200, patience=10, verbose=0, \n",
    "                 model_path=pre_model_path)\n",
    "\n",
    "mlnn_pipe_pt = Pipeline([('scaler', sc), ('re_sample_pt', ros), ('clf', mlnn_pt)])\n",
    "\n",
    "# Define FT MLNN estimator\n",
    "mlnn_ft = SklearnFT(pre_layer=10, n_freeze=0, dense_unit={}, dense_activation={}, dense_dropout={},\n",
    "                 optimizer_name='adam', loss_function='binary_crossentropy', epoch=200, patience=10, verbose=0, \n",
    "                 pre_model=pre_model_path, model_path='keras-models/ros_mlnn_pt_ft_disc_pfi_x_fine.h5')\n",
    "\n",
    "mlnn_pipe_ft = Pipeline([('scaler', sc), ('re_sample_ft', ros), ('clf', mlnn_ft)])\n",
    "\n",
    "# Define Bayesian-Optimization\n",
    "hyper_search = HyperoptCV_TL(estimator_pt=mlnn_pipe_pt, \n",
    "                          X_pt=df_gene_exp_disc, \n",
    "                          y_pt=Y_surv_disc_class, estimator_ft=mlnn_pipe_ft, \n",
    "                          hyper_space=params_space, cv=cv_split, scoring=eval_metric, opt_metric=model_sel_metric, \n",
    "                          n_iter=n_iter, random_seed=random_state, verbose_file = 'class_imb_mlnn_new_pt_ft_verbose.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_trial = hyper_search.model_selection(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__ft_params': {'clf__batch_size': 128,\n",
       "  'clf__lr': 0.007139777328003964,\n",
       "  're_sample_ft__sampling_strategy': 1},\n",
       " 'clf__pt_params': {'clf__batch_size': 128,\n",
       "  'clf__dense_choice': {'clf__add_dense': 0,\n",
       "   'clf__dense_dropout_1': 0.8,\n",
       "   'clf__dense_dropout_2': 0.8,\n",
       "   'clf__dense_unit_1': 2700,\n",
       "   'clf__dense_unit_2': 500},\n",
       "  'clf__lr': 0.0655685703917845,\n",
       "  're_sample_pt__sampling_strategy': 1}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial['result']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F-1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Sens</th>\n",
       "      <th>Spec</th>\n",
       "      <th>Thres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.726901</td>\n",
       "      <td>0.709365</td>\n",
       "      <td>0.308105</td>\n",
       "      <td>0.239307</td>\n",
       "      <td>0.217497</td>\n",
       "      <td>0.611691</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>3.572214e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.056254</td>\n",
       "      <td>0.053412</td>\n",
       "      <td>0.062848</td>\n",
       "      <td>0.064553</td>\n",
       "      <td>0.146852</td>\n",
       "      <td>0.121793</td>\n",
       "      <td>7.001453e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.601613</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.127204</td>\n",
       "      <td>0.144231</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>1.055455e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.665827</td>\n",
       "      <td>0.270499</td>\n",
       "      <td>0.191119</td>\n",
       "      <td>0.170628</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653226</td>\n",
       "      <td>4.917509e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.704354</td>\n",
       "      <td>0.304531</td>\n",
       "      <td>0.232946</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.751613</td>\n",
       "      <td>1.340464e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.749194</td>\n",
       "      <td>0.342919</td>\n",
       "      <td>0.274052</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.701287</td>\n",
       "      <td>0.839568</td>\n",
       "      <td>2.813395e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.847984</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.379760</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>2.786947e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACC        AUC        F-1        MCC       Prec       Sens  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.726901   0.709365   0.308105   0.239307   0.217497   0.611691   \n",
       "std     0.099020   0.056254   0.053412   0.062848   0.064553   0.146852   \n",
       "min     0.467836   0.601613   0.229508   0.127204   0.144231   0.312500   \n",
       "25%     0.660819   0.665827   0.270499   0.191119   0.170628   0.500000   \n",
       "50%     0.728070   0.704354   0.304531   0.232946   0.200000   0.625000   \n",
       "75%     0.815789   0.749194   0.342919   0.274052   0.250000   0.701287   \n",
       "max     0.894737   0.847984   0.437500   0.379760   0.437500   0.937500   \n",
       "\n",
       "            Spec         Thres  \n",
       "count  50.000000  5.000000e+01  \n",
       "mean    0.738827  3.572214e-02  \n",
       "std     0.121793  7.001453e-02  \n",
       "min     0.422078  1.055455e-09  \n",
       "25%     0.653226  4.917509e-05  \n",
       "50%     0.751613  1.340464e-03  \n",
       "75%     0.839568  2.813395e-02  \n",
       "max     0.941935  2.786947e-01  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = best_trial['result']['test_score']\n",
    "res = pd.DataFrame({'AUC': scores['test_auc'], \n",
    "              'ACC': scores['test_acc'], \n",
    "              'Sens': scores['test_sens'], \n",
    "              'Spec': scores['test_spec'],\n",
    "              'Prec': scores['test_prec'],\n",
    "              'F-1': scores['test_f1'],\n",
    "              'MCC': scores['test_mcc'],\n",
    "              'Thres': scores['test_thres']})\n",
    "res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "file_path = 'results/ros_mlnn_new_disc_pfi_lung_ft_100_iter_rep_kfold.csv'\n",
    "res.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
